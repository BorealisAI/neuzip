{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from torch.testing._internal.logging_tensor import LoggingTensorMode, capture_logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$1: bf16[8192] = torch._ops.aten._to_copy.default($0, dtype=torch.bfloat16)\n",
      "$3: bf16[8192, 8192] = torch._ops.aten._to_copy.default($2, dtype=torch.bfloat16)\n",
      "$5: bf16[3, 3, 8192] = torch._ops.aten._to_copy.default($4, dtype=torch.bfloat16)\n",
      "$6: bf16[9, 8192] = torch._ops.aten.view.default($5, ['9', '8192'])\n",
      "$7: bf16[8192, 8192] = torch._ops.aten.t.default($3)\n",
      "$8: bf16[9, 8192] = torch._ops.aten.addmm.default($1, $6, $7)\n",
      "$9: bf16[3, 3, 8192] = torch._ops.aten.view.default($8, ['3', '3', '8192'])\n",
      "$10: bf16[3, 8192] = torch._ops.aten.select.int($9, 0, 0)\n",
      "$11: bf16[8192] = torch._ops.aten.select.int($10, 0, 0)\n",
      "$12: bf16[] = torch._ops.aten.select.int($11, 0, 0)\n",
      "$13: f32[] = torch._ops.aten._to_copy.default($12, dtype=torch.float32)\n",
      "$14: f32[] = torch._ops.aten.ones_like.default($13, pin_memory=False, memory_format=torch.preserve_format)\n",
      "$15: bf16[] = torch._ops.aten._to_copy.default($14, dtype=torch.bfloat16, layout=torch.strided, device=device(type='cuda', index=0))\n",
      "$16: bf16[8192] = torch._ops.aten.select_backward.default($15, ['8192'], 0, 0)\n",
      "$17: bf16[3, 8192] = torch._ops.aten.select_backward.default($16, ['3', '8192'], 0, 0)\n",
      "$18: bf16[3, 3, 8192] = torch._ops.aten.select_backward.default($17, ['3', '3', '8192'], 0, 0)\n",
      "$19: bf16[9, 8192] = torch._ops.aten.view.default($18, ['9', '8192'])\n",
      "$20: bf16[8192, 8192] = torch._ops.aten.t.default($7)\n",
      "$21: bf16[9, 8192] = torch._ops.aten.mm.default($19, $20)\n",
      "$22: bf16[8192, 9] = torch._ops.aten.t.default($19)\n",
      "$23: bf16[8192, 8192] = torch._ops.aten.mm.default($22, $6)\n",
      "$24: bf16[8192, 8192] = torch._ops.aten.t.default($23)\n",
      "$25: bf16[1, 8192] = torch._ops.aten.sum.dim_IntList($19, ['0'], True)\n",
      "$26: bf16[8192] = torch._ops.aten.view.default($25, ['8192'])\n",
      "$27: bf16[8192, 8192] = torch._ops.aten.t.default($24)\n",
      "$28: bf16[3, 3, 8192] = torch._ops.aten.view.default($21, ['3', '3', '8192'])\n",
      "$29: f32[3, 3, 8192] = torch._ops.aten._to_copy.default($28, dtype=torch.float32, layout=torch.strided, device=device(type='cuda', index=0))\n",
      "$30: f32[3, 3, 8192] = torch._ops.aten.detach.default($29)\n",
      "$31: f32[3, 3, 8192] = torch._ops.aten.detach.default($30)\n",
      "$32: f32[8192, 8192] = torch._ops.aten._to_copy.default($27, dtype=torch.float32, layout=torch.strided, device=device(type='cuda', index=0))\n",
      "$33: f32[8192, 8192] = torch._ops.aten.detach.default($32)\n",
      "$34: f32[8192, 8192] = torch._ops.aten.detach.default($33)\n",
      "$35: f32[8192] = torch._ops.aten._to_copy.default($26, dtype=torch.float32, layout=torch.strided, device=device(type='cuda', index=0))\n",
      "$36: f32[8192] = torch._ops.aten.detach.default($35)\n",
      "$37: f32[8192] = torch._ops.aten.detach.default($36)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "hdim = 1024 * 8\n",
    "\n",
    "main_linear = torch.nn.Linear(hdim, hdim).to(device)\n",
    "\n",
    "fp16_linear = copy.deepcopy(main_linear).half()\n",
    "\n",
    "main_inputs = torch.randn(3, 3, hdim).to(device).requires_grad_(True)\n",
    "fp16_inputs = main_inputs.half().requires_grad_(True)\n",
    "\n",
    "# main_linear = main_linear.bfloat16()\n",
    "with capture_logs(is_mode=True) as logs, LoggingTensorMode():\n",
    "\n",
    "    with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "        outputs = main_linear(main_inputs)\n",
    "        loss = outputs[0, 0, 0].float()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "for l in logs:\n",
    "    print(l)\n",
    "\n",
    "# bfloat16 input\n",
    "with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "    outputs = fp16_linear(fp16_inputs)\n",
    "    loss = torch.sum(outputs)\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.equal(fp16_linear.weight.grad, main_linear.weight.grad.half()))\n",
    "print(torch.equal(fp16_linear.weight.grad.float(), main_linear.weight.grad))\n",
    "\n",
    "print(torch.equal(fp16_linear.weight.grad, main_linear.weight.grad.half()))\n",
    "print(torch.equal(fp16_linear.weight.grad.float(), main_linear.weight.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
